\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[bitstream-charter]{mathdesign}
\usepackage{inconsolata}

\usepackage[margin=1.2in]{geometry}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{color}
\definecolor{darkblue}{rgb}{0,0,0.5}
\usepackage[colorlinks=true,linkcolor=darkblue,citecolor=darkblue,urlcolor=darkblue]{hyperref}
\usepackage[noae,nogin]{Sweave}


\title{An Introduction to Events}
\author{Will Lowe\\MZES, University of Mannheim}

%\VignetteIndexEntry{An R package for doing things with events}
%\VignettePackage{events}

\begin{document}
%\SweaveSyntax{SweaveSyntaxLatex}

\maketitle

\section{Introduction}

The \texttt{events} package takes political event data in the form generated by KEDS 
\citep{Schrodtetal1994,Gerneretal1994}.  For this vignette we use the
Reuters-derived event chronology from the collapse of Yugoslavia, focusing 
on Serbian and Bosnian interactions in the period in 1991 and 1995.
The events in this event data are coded according to the WEIS event scheme \citep{WEIS}.
<<load.library,echo=FALSE,fig=FALSE>>=
library(events)
@
In the following sections we perform a typical set of data manipulations; we load 
and clean a set of event data, restrict it to actors and period of interest, apply
a scale to the raw events, aggregate to make a time series and plot the results.
The package does not current contain function for the analysis of event data 
because once the data is finally in a regular time series format, other packages 
can be used to analyse it.  The package provides the link between raw output from
an event data extraction system such as KEDS/TABARI and a set of regularly spaced
time series.

\subsection{Data Loading and Cleaning}

A version of the Balkans data is built into the package.  Here we load and summarise it.
<<read.data,echo=TRUE,fig=FALSE>>=
data("balkans.weis")
summary(balkans.weis)
@
An event data set can be constructed from text file event data output using the
\texttt{read\_keds} function.  And event data set is essentially a data frame with 
column names \texttt{date}, \texttt{source}, \texttt{target}, and \texttt{code}.
<<show.data,echo=TRUE,fig=FALSE>>=
head(balkans.weis)
@
Subsequent columns of event label, shown above, and matching phrase from the original
text, not shown above, are optional.

Duplicated stories are a common type of information extraction error.  We can prefilter 
the events by removing all instances of the same pair of actors experiencing the same event
on the same date using the on-a-day filter
<<one.a.day,echo=TRUE,fig=FALSE>>=
dd1 <- one_a_day(balkans.weis)
@
This can also be applied as part of the \texttt{read\_keds} function. 

\subsection{Actor Filtering}

In the next step we filter out actors whose interactions are not of interest.  
A complete list of actors is given by \texttt{actors} function
<<actors,echo=TRUE,fig=FALSE>>=
head(actors(dd1))
@
The functions \texttt{sources} and \texttt{targets} list actor codes in the corresponding roles, and \texttt{codes} lists all the codes that are used.

We will focus on actors identified in the data as Serbia `SER' and the Serbian military `SERMIL', and Bosnia `BOS' and the Bosnian 
military `BOSMIL'
<<filter.actors,echo=TRUE,fig=FALSE>>=
dd2 <- filter_actors(dd1, fun=spotter("SER", "SERMIL", "BOS", "BOSMIL"))
@
The \texttt{filter\_actors} function takes two arguments, an event data set and a filter function, 
and returns a filtered
event data set.  The filter may be any function that returns TRUE for things that are of 
interest and FALSE otherwise.  Here we have used a convenience function \texttt{spotter}, which creates a function that returns TRUE for any exact matches of its arguments.  

The function takes an optional \texttt{which} argument which can be used to specify that the filtering should apply to `source', `target' or `both', which is the default.

We would like to treat the Serbian and Bosnian actors identified in the previous step as equivalent and refer to then for convenience as `ser' and `bos' respectively.  We do this by aggregating actor codes:
<<aggregate.actors,echo=TRUE,fig=FALSE>>=
actor.agg <- list(ser=c("SER", "SERMIL"), bos=c("BOS", "BOSMIL"))
dd3 <- map_actors(dd2, fun=actor.agg)
@
Here we specify the mapping from new to old actor codes as a list and pass it to the mapping function.  We could also have written a function that for any object returned its new name, in the same style as the filter function in the previous section.  For example
\begin{verbatim}
actor.aggregator <- function(oldname){ 
    newname <- NA
    if (oldname %in% c("SER", "SERMIL")) newname <- "ser"
    if (oldname %in% c("BOS", "BOSMIL")) newname <- "bos"
    return(newname)
}
\end{verbatim}
would work, but it's rather longwinded.

\subsection{Temporal Restriction}

We will focus on the period between January 1991 and December 1995
<<filter.time,echo=TRUE,fig=FALSE>>=
dd4 <- filter_time(dd3, start="1991-01-01", end="1995-12-30")
@
The optional \texttt{start} and \texttt{end} parameters may be anything that can be converted into a \texttt{Date} object.

The new data set is considerably smaller than before
<<summary,echo=TRUE,fig=FALSE>>=
summary(dd4)
@

\subsection{Scaling}

Scales are mappings from event codes to real numbers.  You can create your own event code by constructing 
a headerless csv file with event codes in the first column and numbers in the second column, and reading it in with the \texttt{make\_scale} command.  This is a thin wrapper around the \texttt{read.csv} function.  

Here we will use the extended Goldstein scale bundled with the package \citep{Goldstein1992}\footnote{These codes are taken from \href{http://web.ku.edu/~keds/data.dir/KEDS.WEIS.Codes.txt}{http://web.ku.edu/~keds/data.dir/KEDS.WEIS.Codes.txt}}.  This maps WEIS event codes onto a number representing level of conflict or cooperation.
<<intro.scaling,echo=TRUE,fig=FALSE>>=
data("weis.goldstein.scale")
summary(weis.goldstein.scale)
@
When we apply the scale to an event data set a column is added with the same name as the scale
<<add.scale,echo=TRUE,fig=FALSE>>=
dd5 <- add_eventscale(dd4, weis.goldstein.scale)
head(dd5)
@

\subsubsection{Score Aggregation}

The final step is to aggregate quantities of interest into a regular time series for each directed pair of actors.  Here we construct a typical dyad set using the summed scored event counts per week:
<<aggregate.scores,echo=TRUE,fig=FALSE>>=
dyads <- make_dyads(dd5, scale="goldstein", unit="week", monday=TRUE, 
		fun=sum, missing.data=0)
@
We are asserting here that weekly counts should start on a monday, that they should be summed rather than e.g. averaged, and that weeks with no events observed should be given score zero.  Note that this is only an example; these are not necessarily sensible setting for actual applications.  

Alternative aggregation units are `day', `month', `quarter', and `year'.  The fun parameter should be any function that will transform a numerical vector into a scalar.

The output of \texttt{make\_dyads} is a list of directed dyad time series.  All combinations of actors are constructed, so it is a good idea to filter and aggregate actors before calling the function.  The naming scheme for the dyads is concatenation with a period: \texttt{dyads\$ser.bos} is the temporally aggregated sequence of summed scores with the `ser' actor as source and `bos' the target, \texttt{dyads\$bos.ser} is the reverse direction, and  \texttt{dyads\$ser.ser} is the activities internal to the `ser' actor.  
<<dyads,echo=TRUE,fig=FALSE>>=
tail(dyads$ser.bos)
@
The directed dyad can be treated like a regular time series:
<<serbos,echo=TRUE,fig=TRUE,width=6.5,height=3.5>>=
with(dyads$ser.bos, plot(goldstein ~ date, type="l", lwd=2))
@
There are a few gaps in this series.  This is because the scale does not cover all the events that occur in the event data.  We can investigate this further with
<<gaps,echo=TRUE,fig=FALSE>>=
scale_coverage(weis.goldstein.scale, dd5)
@

\subsubsection{Count Aggregation}

If \texttt{scale} is NULL a sequence then directed dyadic event count streams are created instead of scaled scores.  This will generate an event count for each distinct event code and each temporal unit.  Sometimes it is helpful to aggregate code before constructing these count streams.    Here we aggregate them into four categories: verbal and material cooperation, and verbal and material conflict
<<event.aggregation,echo=TRUE,fig=FALSE>>=
evts <- codes(dd4)
event.agg <- list(
    coop.verb=grep("02.|03.|04.|05.|08.|09.|10.", evts, value=TRUE),
    coop.mat=grep("01.|06.|07.", evts, value=TRUE),
    conf.verb=grep("11.|12.|13.|14.|15.|16.|17.", evts, value=TRUE),
    conf.mat=grep("18.|19.|20.|21.|22.", evts, value=TRUE)
)
dc1 <- map_codes(dd4, fun=event.agg)
@
Like the other aggregation function, \texttt{map\_codes} function in the final line takes a list or a function to map old event codes to new ones.  We start by using the \texttt{codes} function to list all the event codes that are used in the data.  WEIS is a two level scheme that by convention indicates the upper level code category in first two digits and subcategory in remaining digits.  Here, we use \texttt{grep} to identify all the codes in ``01'', ``06'', and ``07'' at any level and assign them to a new material cooperation category \texttt{mat.coop}.
<<make.dyads,echo=TRUE,fig=FALSE>>=
dyad.counts <- make_dyads(dc1, scale=NULL, unit="week", monday=TRUE, 
		fun=sum, missing.data=0)
tail(dyad.counts$ser.bos)
@

\bibliographystyle{apalike}
\bibliography{events}

\end{document}

